{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46fae5af",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Total_crawling' object has no attribute 'html'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-c8c358852931>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTotal_crawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msbsports\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-c8c358852931>\u001b[0m in \u001b[0;36msbsports\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://www.sbsports.or.kr/sub/wrcAble.do\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitial_setting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msitename\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmy_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mdf_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[0mtb_name_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhtmlAll\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"caption\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Total_crawling' object has no attribute 'html'"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "\n",
    "class Total_crawling():\n",
    "    def __init__(self):\n",
    "        # self.dic={}\n",
    "        # self.name_dic={}\n",
    "        # self.my_columns = []\n",
    "        # self.sitename = \"\"\n",
    "        pass\n",
    "    \n",
    "    ##초기 변수 셋팅\n",
    "    def initial_setting(self,sitename,col_list):\n",
    "        self.dic={}\n",
    "        self.my_columns = col_list\n",
    "        for col in self.my_columns:\n",
    "            self.dic[col]=list()\n",
    "        self.name_dic={\"구분\":[]}\n",
    "        self.sitename = sitename\n",
    "\n",
    "\n",
    "    ## 프로그램 사이트 url 찾기\n",
    "    def find_data(self,url,elem_func,program_page=\"\"):\n",
    "        self.html = requests.get(url+program_page).text\n",
    "        self.htmlAll = bs(self.html,'html.parser')\n",
    "        self.finded_data = elem_func\n",
    "        return self.finded_data\n",
    "\n",
    "    \n",
    "    ## dic, name_dic 변수에 데이터 추가\n",
    "    def col_append_data(self, df, grogram_name_func, current_col=[], differ_col = []):\n",
    "        if len(current_col) == 0:\n",
    "            current_col = df.columns.tolist()\n",
    "\n",
    "        for col in current_col:\n",
    "            for value in df[col]:\n",
    "                self.dic[col].append(value)\n",
    "        if len(differ_col) == 0:\n",
    "            for differ in differ_col:\n",
    "                for _ in range(len(df[col])):\n",
    "                    self.dic[differ].append(\"\")\n",
    "        for _ in range(len(df[current_col[0]].values)):\n",
    "            self.name_dic[\"구분\"].append(grogram_name_func)\n",
    "    \n",
    "    def dic_to_csv(self):\n",
    "        sort_columns = list(self.my_columns)\n",
    "        sort_columns.insert(0,\"구분\")\n",
    "        result_df = pd.DataFrame(self.dic)\n",
    "        result_df = result_df[sort_columns]\n",
    "        result_df = result_df.dropna(axis=0)# 결측값 행 제거\n",
    "        result_df.to_csv('./{}.csv'.format(self.sitename), sep=',', na_rep='NaN',encoding=\"CP949\", index=False)\n",
    "\n",
    "    def sbsports(self):##서부재활체육센터\n",
    "        sitename = \"서부재활체육센터\"\n",
    "        my_columns = [\"프로그램\", \"대상\",\"참가요일\",\"시간\",\"회비\"]\n",
    "        url = \"http://www.sbsports.or.kr/sub/wrcAble.do\"\n",
    "        self.initial_setting(sitename,my_columns)\n",
    "        df_list = self.find_data(url,pd.read_html(self.html,header=0))\n",
    "        tb_name_list = [x.text.strip() for x in self.htmlAll.find_all(\"caption\")]\n",
    "\n",
    "        for i in range(len(tb_name_list)):#len(df_list)\n",
    "            ##현재 테이블의 컬럼 가져오기\n",
    "            current_col = df_list[i].columns.tolist()\n",
    "            for name in current_col:\n",
    "                df_list[i]=df_list[i].rename({name:name.replace(\" \",\"\")},axis=1)\n",
    "            current_col = df_list[i].columns.tolist()\n",
    "            print(current_col)\n",
    "\n",
    "            for col in current_col:\n",
    "                if col == \"비고\":\n",
    "                    current_col.remove(col)\n",
    "                elif col == \"구분\":\n",
    "                    df_list[i]=df_list[i].rename({col:\"프로그램\"},axis=1)\n",
    "                    current_col.remove(col)\n",
    "                    current_col.append(\"프로그램\")\n",
    "                elif col == \"참가요일 및 시간\":\n",
    "                    df_list[i]=df_list[i].rename({col:\"참가요일\"},axis=1)\n",
    "                    current_col.remove(col)\n",
    "                    current_col.append(\"참가요일\")\n",
    "                elif col == \"정원\":\n",
    "                    current_col.remove(col)\n",
    "        \n",
    "            inter_col = list(set(self.my_columns) & set(current_col))\n",
    "            differ_col = list(set(self.my_columns).difference(current_col))\n",
    "\n",
    "            self.col_append_data(df_list[i],tb_name_list[i][:-3]+\"프로그램\" if tb_name_list[i].find(\"테이블\")!=-1 else tb_name_list[i], current_col = inter_col, differ_col = differ_col)\n",
    "        self.dic.update(self.name_dic)\n",
    "        self.dic_to_csv()\n",
    "\n",
    "\n",
    "s = Total_crawling()\n",
    "s.sbsports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf47891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
